{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CovidAID.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsV0vtgahuKbRMNgYys2yx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaekay/CovidAID/blob/master/CovidAID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV6y4tzLax6J",
        "colab_type": "text"
      },
      "source": [
        "### Enable GPU first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh6Kx4aR_6JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_huWwDAtAGS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./CovidAID\n",
        "!git clone --recursive https://github.com/aaekay/CovidAID.git\n",
        "!wget https://sogppg.bl.files.1drv.com/y4m7xCVzOJm2tZO9UttZgEidLVEYUsYqN4zjak7oGSlj9k75JYCOwQNF-NXmkolYeS0oUJ8STXyq5wKG7SHTBXF_uRXefR4FbA0x8-b-lQVHNVqp5Ts72XLkxvG4R6Z_EonfAX-XYeSRpkSgmOVqXGVCCOB-GQAbnxrpi0TdvZB4--kBMLqtLe7ESNTaruxnOpjt7z466AvplCvYc8UtdO86Q\n",
        "!mv /content/y4m7xCVzOJm2tZO9UttZgEidLVEYUsYqN4zjak7oGSlj9k75JYCOwQNF-NXmkolYeS0oUJ8STXyq5wKG7SHTBXF_uRXefR4FbA0x8-b-lQVHNVqp5Ts72XLkxvG4R6Z_EonfAX-XYeSRpkSgmOVqXGVCCOB-GQAbnxrpi0TdvZB4--kBMLqtLe7ESNTaruxnOpjt7z466AvplCvYc8UtdO86Q pneumo.zip\n",
        "!unzip ./pneumo.zip -d ./CovidAID/chest-xray-pneumonia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dOHiUG8Yc2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for installing the torch version 0.3.0\n",
        "!wget https://download.pytorch.org/whl/cu75/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNW-2tWjYltQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install /content/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJj1gtqsUaAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is for installing requirements\n",
        "!pip install -r /content/CovidAID/requirements.txt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efvmat8xGAUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 /content/CovidAID/data_tools/prepare_covid_data.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TLX_zIvFK3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 /content/CovidAID/data_tools/prepare_data.py --combine_pneumonia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ_HF4b-xl50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 /content/CovidAID/tools/transfer.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqthpdkPCLug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKbU2qfyC8lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bonNxt0K0Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 ./CovidAID/tools/trainer.py --mode train --freeze --checkpoint ./CovidAID/models/CovidAID_3_class.pth --bs 16 --save ./new_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJVj9pjQt1ja",
        "colab_type": "text"
      },
      "source": [
        "### Now preparing for the covid data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiYjJ8UbtzkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP39_G19t8YL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COVID_DATA_PATH='./CovidAID/covid-chestxray-dataset'\n",
        "METADATA_CSV = os.path.join(COVID_DATA_PATH, 'metadata.csv')\n",
        "TRAIN_FILE = './CovidAID/data/covid19/train_list.txt'\n",
        "VAL_FILE = './CovidAID/data/covid19/val_list.txt'\n",
        "TEST_FILE = './CovidAID/data/covid19/test_list.txt'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udPg8oxct-WU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load patient stats\n",
        "covids = dict()\n",
        "df = pd.read_csv(METADATA_CSV)\n",
        "df = df[(df['finding'] == 'COVID-19') & (df['modality'] == 'X-ray') & (\n",
        "                (df['view'] == 'PA') | (df['view'] == 'AP') | (df['view'] == 'AP Supine')\n",
        "            )]\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfyLsMQuuA27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patient_ids = Counter(df['patientid'].tolist())\n",
        "covids = {k: v for k, v in sorted(patient_ids.items(), key=lambda item: item[1])}\n",
        "total_data = sum([v for k,v in covids.items()])\n",
        "print (\"Patient-#X-Rays statistics:\")\n",
        "print (covids)\n",
        "print (\"Total Images:\", total_data, '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmC2fZUgukVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign train-val-test split\n",
        "test_patients = set({4, 15, 86, 59, 6, 82, 80, 78, 76, 65, 36, 32, 50, 18, 115, 152, 138, 70, 116})\n",
        "val_patients = set({73, 51, 48, 11, 43, 24, 112})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DzDlQMUul80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ('#Train patients:', len(set(covids.keys()).difference(test_patients.union(val_patients))))\n",
        "print ('#Test patients:', len(test_patients))\n",
        "print ('#Val patients:', len(val_patients))\n",
        "print ()\n",
        "print ('#Train data points:', sum([v for k, v in covids.items() if int(k) not in test_patients.union(val_patients)]))\n",
        "print ('#Test data points:', sum([v for k, v in covids.items() if int(k) in test_patients]))\n",
        "print ('#Val data points:', sum([v for k, v in covids.items() if int(k) in val_patients]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGbZHnJBuve9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct the split lists\n",
        "train_list = []\n",
        "test_list = []\n",
        "val_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvdjf9dkuzjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, row in df.iterrows():\n",
        "    patient_id = row['patientid']\n",
        "    filename = os.path.join(row['folder'], row['filename'])\n",
        "\n",
        "    if int(patient_id) in test_patients:\n",
        "        test_list.append(filename)\n",
        "    elif int(patient_id) in val_patients:\n",
        "        val_list.append(filename)\n",
        "    else:\n",
        "        train_list.append(filename)\n",
        "\n",
        "print (len(train_list), len(test_list), len(val_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68W-5zLYu55D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write image list in file\n",
        "def make_img_list(data_file, img_file_list):\n",
        "    with open(data_file, 'w') as f:\n",
        "        for imgfile in img_file_list:\n",
        "            try: \n",
        "                assert os.path.isfile(os.path.join(COVID_DATA_PATH, imgfile))\n",
        "                f.write(\"%s\\n\" % imgfile)\n",
        "            except: \n",
        "                print (\"Image %s NOT FOUND\" % imgfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A03By7JzvBmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_img_list(TRAIN_FILE, train_list)\n",
        "make_img_list(VAL_FILE, val_list)\n",
        "make_img_list(TEST_FILE, test_list)\n",
        "TRAIN_FILE, train_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8rt09f8vjTU",
        "colab_type": "text"
      },
      "source": [
        "### Prepare combined dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSG5xslOiEoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Script to prepare combined dataset\n",
        "Class 0: Normal\n",
        "Class 1: Bacterial Pneumonia\n",
        "Class 2: Viral Pneumonia\n",
        "Class 3: COVID-19\n",
        "\"\"\"\n",
        "import glob\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--combine_pneumonia\", action='store_true', default=False)\n",
        "args = parser.parse_args()\n",
        "\n",
        "COVID19_DATA_PATH = \"./CovidAID/data/covid19\"\n",
        "COVID19_IMGS_PATH = \"./CovidAID/covid-chestxray-dataset\"\n",
        "PNEUMONIDA_DATA_PATH = \"./CovidAID/chest-xray-pneumonia\"\n",
        "DATA_PATH = \"./CovidAID/data\"\n",
        "\n",
        "# Assert that the data directories are present\n",
        "for d in [COVID19_DATA_PATH, COVID19_IMGS_PATH, PNEUMONIDA_DATA_PATH, DATA_PATH]:\n",
        "    try:\n",
        "        assert os.path.isdir(d) \n",
        "    except:\n",
        "        print (\"Directory %s does not exists\" % d)\n",
        "\n",
        "def create_list (split):\n",
        "    assert split in ['train', 'test', 'val']\n",
        "\n",
        "    l = []\n",
        "    # Prepare list using kaggle pneumonia dataset\n",
        "    for f in glob.glob(os.path.join(PNEUMONIDA_DATA_PATH, split, 'NORMAL', '*')):\n",
        "        l.append((f, 0)) # Class 0\n",
        "\n",
        "    for f in glob.glob(os.path.join(PNEUMONIDA_DATA_PATH, split, 'PNEUMONIA', '*')):\n",
        "        if args.combine_pneumonia:\n",
        "            l.append((f, 1)) # Class 1\n",
        "        else:\n",
        "            if 'bacteria' in f:\n",
        "                l.append((f, 1)) # Class 1\n",
        "            else:\n",
        "                l.append((f, 2)) # Class 2\n",
        "\n",
        "    # Prepare list using covid dataset\n",
        "    covid_file = os.path.join(COVID19_DATA_PATH, '%s_list.txt'%split)\n",
        "    with open(covid_file, 'r') as cf:\n",
        "        for f in cf.readlines():\n",
        "            f = os.path.join(COVID19_IMGS_PATH, f.strip())\n",
        "            if args.combine_pneumonia:\n",
        "                l.append((f, 2)) # Class 2\n",
        "            else:\n",
        "                l.append((f, 3)) # Class 3\n",
        "\n",
        "    with open(os.path.join(DATA_PATH, '%s.txt'%split), 'w') as f:\n",
        "        for item in l:\n",
        "            f.write(\"%s %d\\n\" % item)\n",
        "\n",
        "for split in ['train', 'test', 'val']:\n",
        "    create_list(split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdqByWKnqW5p",
        "colab_type": "text"
      },
      "source": [
        "### Prepare pretrained layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZSUi_nVqbdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Code to transfer weights from CheXNet (torch 0.3) to CovidAID\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "from covidaid import CovidAID, CheXNet\n",
        "import torch\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--combine_pneumonia\", action='store_true', default=False)\n",
        "parser.add_argument(\"--chexnet_model_checkpoint\", \"--old\", type=str, default=\"./CovidAID/data/CheXNet_model.pth.tar\")\n",
        "parser.add_argument(\"--covidaid_model_trained_checkpoint\", \"--new\", type=str, default=\"./CovidAID/models/CovidAID_transfered.pth.tar\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "chexnet_model_checkpoint = args.chexnet_model_checkpoint\n",
        "covidaid_model_trained_checkpoint = args.covidaid_model_trained_checkpoint\n",
        "\n",
        "model = CovidAID(combine_pneumonia=args.combine_pneumonia)\n",
        "\n",
        "def load_weights(checkpoint_pth, state_dict=True):\n",
        "    model = torch.load(checkpoint_pth)\n",
        "    \n",
        "    if state_dict:\n",
        "        return model['state_dict']\n",
        "    else:\n",
        "        return model\n",
        "\n",
        "def get_top_keys(model, depth=0):\n",
        "    return set({w.split('.')[depth] for w in model.keys()})\n",
        "\n",
        "chexnet_model = load_weights(chexnet_model_checkpoint)\n",
        "template = model.state_dict()\n",
        "\n",
        "assert get_top_keys(chexnet_model, depth=2) == set({'features', 'classifier'})\n",
        "assert get_top_keys(template, depth=1) == set({'features', 'classifier'})\n",
        "\n",
        "# print (chexnet_model.keys())\n",
        "# print (template.keys())\n",
        "# print (model.state_dict().keys())\n",
        "\n",
        "c_keys = {k for k in chexnet_model.keys()}\n",
        "t_keys = {'module.' + k for k in template.keys()}\n",
        "\n",
        "assert len(c_keys.difference(t_keys)) == 0\n",
        "assert len(t_keys.difference(c_keys)) == 0\n",
        "\n",
        "\n",
        "# Transfer the feature weights\n",
        "for k, w in template.items():\n",
        "    chex_key = 'module.' + k\n",
        "\n",
        "    if k.split('.')[1] == 'classifier':\n",
        "        # Uncomment below to copy trained weights of pneumonia\n",
        "        # 6th class is pneumonia in CheXNet => Copy it's weights to pneumonia classes\n",
        "        # for c in [1, 2, 3]:\n",
        "        #     template[k][c, ...] = chexnet_model[chex_key][6, ...]\n",
        "        print ('doing nothing for', k)\n",
        "    else:\n",
        "        # print (type(template[k]), template[k].size())\n",
        "        # print (type(chexnet_model[chex_key]), chexnet_model[chex_key].size())\n",
        "        assert chexnet_model[chex_key].size() == template[k].size()\n",
        "        template[k] = chexnet_model[chex_key]\n",
        "\n",
        "torch.save(template, covidaid_model_trained_checkpoint)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbXd7BsBq6KJ",
        "colab_type": "text"
      },
      "source": [
        "### training the classifier layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knr2eKizq-QY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Trainer for training and testing the networks\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import datetime\n",
        "import json\n",
        "import argparse\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch import optim\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from read_data import ChestXrayDataSet, ChestXrayDataSetTest\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc, f1_score\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from covidaid import CovidAID\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Trainer:\n",
        "    def __init__ (self, local_rank=None, checkpoint=None, combine_pneumonia=False):\n",
        "        \"\"\"\n",
        "        Trainer for the CovidAID\n",
        "        \"\"\"\n",
        "        self.distributed = True if local_rank is not None else False\n",
        "        print (\"Distributed training %s\" % ('ON' if self.distributed else 'OFF'))\n",
        "        if self.distributed:\n",
        "            raise NotImplementedError(\"Currently distributed training not supported\")\n",
        "            self.device = torch.cuda.device('cuda', local_rank)\n",
        "        else:\n",
        "            self.device = torch.cuda.device('cuda')\n",
        "\n",
        "        # Using 2 classes for pneumonia vs 1 class\n",
        "        self.combine_pneumonia = combine_pneumonia\n",
        "\n",
        "        # self.net = CovidAID().to(self.device)\n",
        "        self.net = CovidAID(combine_pneumonia).cuda()\n",
        "        if self.distributed:\n",
        "            self.net = torch.nn.parallel.DistributedDataParallel(self.net,\n",
        "                                                            device_ids=[local_rank],\n",
        "                                                            output_device=local_rank)\n",
        "        \n",
        "        # load model\n",
        "        if checkpoint is not None:\n",
        "            self.load_model(checkpoint)\n",
        "\n",
        "    def train(self, TRAIN_IMAGE_LIST, VAL_IMAGE_LIST, NUM_EPOCHS=10, LR=0.001, BATCH_SIZE=64,\n",
        "                start_epoch=0, logging=True, save_path=None, freeze_feature_layers=True):\n",
        "        \"\"\"\n",
        "        Train the CovidAID\n",
        "        \"\"\"\n",
        "        normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                     [0.229, 0.224, 0.225])\n",
        "\n",
        "        train_dataset = ChestXrayDataSet(image_list_file=TRAIN_IMAGE_LIST,\n",
        "                                        transform=transforms.Compose([\n",
        "                                            transforms.Resize(256),\n",
        "                                            transforms.TenCrop(224),\n",
        "                                            transforms.Lambda\n",
        "                                            (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "                                            transforms.Lambda\n",
        "                                            (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
        "                                        ]),\n",
        "                                        combine_pneumonia=self.combine_pneumonia)\n",
        "        if self.distributed:\n",
        "            sampler = DistributedSampler(train_dataset)\n",
        "            train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False, num_workers=8, pin_memory=True,\n",
        "                                    sampler=sampler)\n",
        "        else:\n",
        "            train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,\n",
        "                                    shuffle=True, num_workers=8, pin_memory=True)\n",
        "\n",
        "        val_dataset = ChestXrayDataSet(image_list_file=VAL_IMAGE_LIST,\n",
        "                                        transform=transforms.Compose([\n",
        "                                            transforms.Resize(256),\n",
        "                                            transforms.TenCrop(224),\n",
        "                                            transforms.Lambda\n",
        "                                            (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "                                            transforms.Lambda\n",
        "                                            (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
        "                                        ]),\n",
        "                                        combine_pneumonia=self.combine_pneumonia)\n",
        "        if self.distributed:\n",
        "            sampler = DistributedSampler(val_dataset)\n",
        "            val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False, num_workers=8, pin_memory=True,\n",
        "                                    sampler=sampler)\n",
        "        else:\n",
        "            val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,\n",
        "                                    shuffle=True, num_workers=8, pin_memory=True)\n",
        "\n",
        "        # Freeze heads and create optimizer\n",
        "        if freeze_feature_layers:\n",
        "            print (\"Freezing feature layers\")\n",
        "            for param in self.net.densenet121.features.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # optimizer = optim.SGD(filter(lambda p: p.requires_grad, self.net.parameters()),\n",
        "        #                 lr=LR, momentum=0.9)\n",
        "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.net.parameters()), lr=LR)\n",
        "\n",
        "\n",
        "        for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "            # switch to train mode\n",
        "            self.net.train()\n",
        "            tot_loss = 0.0\n",
        "            for i, (inputs, target) in tqdm(enumerate(train_loader), total=len(train_dataset)/BATCH_SIZE):\n",
        "                # inputs = inputs.to(self.device)\n",
        "                # target = target.to(self.device)\n",
        "                inputs = inputs.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "                # Shape of input == [BATCH_SIZE, NUM_CROPS=19, CHANNELS=3, HEIGHT=224, WIDTH=244]\n",
        "                bs, n_crops, c, h, w = inputs.size()\n",
        "                inputs = inputs.view(-1, c, h, w)\n",
        "                inputs = torch.autograd.Variable(inputs.view(-1, c, h, w))\n",
        "                target = torch.autograd.Variable(target)\n",
        "                preds = self.net(inputs).view(bs, n_crops, -1).mean(dim=1)\n",
        "\n",
        "                # loss = torch.sum(torch.abs(preds - target) ** 2)    \n",
        "                loss = train_dataset.loss(preds, target)  \n",
        "                # exit()          \n",
        "                tot_loss += float(loss.data)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            tot_loss /= len(train_dataset)\n",
        "\n",
        "            # Clear cache\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "            # Running on validation set\n",
        "            self.net.eval()\n",
        "            val_loss = 0.0\n",
        "            for i, (inputs, target) in tqdm(enumerate(val_loader), total=len(val_dataset)/BATCH_SIZE):\n",
        "                # inputs = inputs.to(self.device)\n",
        "                # target = target.to(self.device)\n",
        "                inputs = inputs.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "                # Shape of input == [BATCH_SIZE, NUM_CROPS=19, CHANNELS=3, HEIGHT=224, WIDTH=244]\n",
        "                bs, n_crops, c, h, w = inputs.size()\n",
        "                inputs = inputs.view(-1, c, h, w)\n",
        "                inputs = torch.autograd.Variable(inputs.view(-1, c, h, w), volatile=True)\n",
        "                target = torch.autograd.Variable(target, volatile=True)\n",
        "\n",
        "                preds = self.net(inputs).view(bs, n_crops, -1).mean(1)\n",
        "                # loss = torch.sum(torch.abs(preds - target) ** 2)\n",
        "                loss = val_dataset.loss(preds, target) \n",
        "                \n",
        "                val_loss += float(loss.data)\n",
        "\n",
        "            val_loss /= len(val_dataset)\n",
        "\n",
        "            # Clear cache\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            # logging statistics\n",
        "            timestamp = str(datetime.datetime.now()).split('.')[0]\n",
        "            log = json.dumps({\n",
        "                'timestamp': timestamp,\n",
        "                'epoch': epoch+1,\n",
        "                'train_loss': float('%.5f' % tot_loss),\n",
        "                'val_loss': float('%.5f' % val_loss),\n",
        "                'lr': float('%.6f' % LR)\n",
        "            })\n",
        "            if logging:\n",
        "                print (log)\n",
        "\n",
        "            log_file = os.path.join(save_path, 'train.log')\n",
        "            if log_file is not None:\n",
        "                with open(log_file, 'a') as f:\n",
        "                    f.write(\"{}\\n\".format(log))\n",
        "\n",
        "            model_path = os.path.join(save_path, 'epoch_%d.pth'%(epoch+1))\n",
        "            self.save_model(model_path)\n",
        "            \n",
        "        print ('Finished Training')\n",
        "\n",
        "    def predict(self, TEST_IMAGE_LIST, BATCH_SIZE=64):\n",
        "        \"\"\"\n",
        "        Predict the task labels corresponding to the input images\n",
        "        \"\"\"\n",
        "        normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                     [0.229, 0.224, 0.225])\n",
        "\n",
        "        test_dataset = ChestXrayDataSetTest(image_list_file=TEST_IMAGE_LIST,\n",
        "                                        transform=transforms.Compose([\n",
        "                                            transforms.Resize(256),\n",
        "                                            transforms.TenCrop(224),\n",
        "                                            transforms.Lambda\n",
        "                                            (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "                                            transforms.Lambda\n",
        "                                            (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
        "                                        ]),\n",
        "                                        combine_pneumonia=self.combine_pneumonia)\n",
        "        if self.distributed:\n",
        "            sampler = DistributedSampler(test_dataset)\n",
        "            test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,\n",
        "                                shuffle=False, num_workers=8, pin_memory=True,\n",
        "                                sampler=sampler)\n",
        "        else:\n",
        "            test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,\n",
        "                                shuffle=True, num_workers=8, pin_memory=True)\n",
        "\n",
        "        # initialize the ground truth and output tensor\n",
        "        gt = torch.FloatTensor().cuda()\n",
        "        pred = torch.FloatTensor().cuda()\n",
        "\n",
        "        # switch to evaluate mode\n",
        "        self.net.eval()\n",
        "\n",
        "        for i, (inputs, target) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            # inputs = inputs.to(self.device)\n",
        "            # target = target.to(self.device)\n",
        "            inputs = inputs.cuda()\n",
        "            target = target.cuda()\n",
        "            gt = torch.cat((gt, target), 0)\n",
        "\n",
        "            # Shape of input == [BATCH_SIZE, NUM_CROPS=19, CHANNELS=3, HEIGHT=224, WIDTH=244]\n",
        "            bs, n_crops, c, h, w = inputs.size()\n",
        "            inputs = torch.autograd.Variable(inputs.view(-1, c, h, w), volatile=True)\n",
        "\n",
        "            # Pass through the network and take average prediction from all the crops\n",
        "            output = self.net(inputs)\n",
        "            output_mean = output.view(bs, n_crops, -1).mean(1)\n",
        "            pred = torch.cat((pred, output_mean.data), 0)\n",
        "        gt = gt.cpu().numpy()\n",
        "        pred = pred.cpu().numpy()\n",
        "\n",
        "        return gt, pred\n",
        "\n",
        "    def evaluate(self, TEST_IMAGE_LIST, BATCH_SIZE=64, cm_path='cm', roc_path='roc'):\n",
        "        \"\"\"\n",
        "        Evaluate on the test set plotting confusion matrix and roc curves\n",
        "        \"\"\"\n",
        "        gt, pred = self.predict(TEST_IMAGE_LIST, BATCH_SIZE=64)\n",
        "        print (pred)\n",
        "\n",
        "        # Compute ROC scores\n",
        "        labels = ['Normal', 'Bacterial', 'Viral', 'COVID-19']\n",
        "        if self.combine_pneumonia:\n",
        "            labels = ['Normal', 'Pneumonia', 'COVID-19']\n",
        "        self.compute_AUC_scores(gt, pred, labels)\n",
        "\n",
        "        # Plot ROC scores\n",
        "        self.plot_ROC_curve(gt, pred, labels, roc_path)\n",
        "\n",
        "        # Treat the max. output as prediction. \n",
        "        # Plot Confusion Matrix\n",
        "        gt = gt.argmax(axis=1)\n",
        "        pred = pred.argmax(axis=1)\n",
        "        self.plot_confusion_matrix(gt, pred, labels, cm_path)\n",
        "\n",
        "    def F1(self, TEST_DIR, out_file, BATCH_SIZE=64):\n",
        "        \"\"\"\n",
        "        Evaluate on multiple test sets and compute F1 scores\n",
        "        \"\"\"\n",
        "        f = open(out_file, 'w')\n",
        "        for test_file in glob.glob(os.path.join(TEST_DIR, '*.txt')):\n",
        "            print (test_file)\n",
        "            gt, pred = self.predict(test_file, BATCH_SIZE)\n",
        "            # Treat the max. output as prediction. \n",
        "            gt = gt.argmax(axis=1)\n",
        "            pred = pred.argmax(axis=1)\n",
        "            f1 = f1_score(gt, pred, average='macro')\n",
        "            f.write('%s %.6f\\n' % (test_file, f1))\n",
        "        f.close()\n",
        "\n",
        "    def plot_confusion_matrix(self, y_true, y_pred, labels, cm_path):\n",
        "        norm_cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
        "        norm_df_cm = pd.DataFrame(norm_cm, index=labels, columns=labels)\n",
        "        plt.figure(figsize = (10,7))\n",
        "        sn.heatmap(norm_df_cm, annot=True, fmt='.2f', square=True, cmap=plt.cm.Blues)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Ground Truth\")\n",
        "        matplotlib.rcParams.update({'font.size': 14})\n",
        "        plt.savefig('%s_norm.png' % cm_path, pad_inches = 0, bbox_inches='tight')\n",
        "        \n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        # Finding the annotations\n",
        "        cm = cm.tolist()\n",
        "        norm_cm = norm_cm.tolist()\n",
        "        annot = [\n",
        "            [(\"%d (%.2f)\" % (c, nc)) for c, nc in zip(r, nr)]\n",
        "            for r, nr in zip(cm, norm_cm)\n",
        "        ]\n",
        "        plt.figure(figsize = (10,7))\n",
        "        sn.heatmap(norm_df_cm, annot=annot, fmt='', cbar=False, square=True, cmap=plt.cm.Blues)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Ground Truth\")\n",
        "        matplotlib.rcParams.update({'font.size': 14})\n",
        "        plt.savefig('%s.png' % cm_path, pad_inches = 0, bbox_inches='tight')\n",
        "        print (cm)\n",
        "\n",
        "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "        print (\"Accuracy: %.5f\" % accuracy)\n",
        "\n",
        "    def compute_AUC_scores(self, y_true, y_pred, labels):\n",
        "        \"\"\"\n",
        "        Computes the Area Under the Curve (AUC) from prediction scores\n",
        "        y_true.shape  = [n_samples, n_classes]\n",
        "        y_preds.shape = [n_samples, n_classes]\n",
        "        labels.shape  = [n_classes]\n",
        "        \"\"\"\n",
        "        AUROC_avg = roc_auc_score(y_true, y_pred)\n",
        "        print('The average AUROC is {AUROC_avg:.4f}'.format(AUROC_avg=AUROC_avg))\n",
        "        for y, pred, label in zip(y_true.transpose(), y_pred.transpose(), labels):\n",
        "            print('The AUROC of {0:} is {1:.4f}'.format(label, roc_auc_score(y, pred)))\n",
        "\n",
        "    def plot_ROC_curve(self, y_true, y_pred, labels, roc_path): \n",
        "        \"\"\"\n",
        "        Plots the ROC curve from prediction scores\n",
        "        y_true.shape  = [n_samples, n_classes]\n",
        "        y_preds.shape = [n_samples, n_classes]\n",
        "        labels.shape  = [n_classes]\n",
        "        \"\"\"\n",
        "        n_classes = len(labels)\n",
        "        # Compute ROC curve and ROC area for each class\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for y, pred, label in zip(y_true.transpose(), y_pred.transpose(), labels):\n",
        "            fpr[label], tpr[label], _ = roc_curve(y, pred)\n",
        "            roc_auc[label] = auc(fpr[label], tpr[label])\n",
        "\n",
        "        # First aggregate all false positive rates\n",
        "        all_fpr = np.unique(np.concatenate([fpr[label] for label in labels]))\n",
        "\n",
        "        # Then interpolate all ROC curves at this points\n",
        "        mean_tpr = np.zeros_like(all_fpr)\n",
        "        for label in labels:\n",
        "            mean_tpr += interp(all_fpr, fpr[label], tpr[label])\n",
        "\n",
        "        # Finally average it and compute AUC\n",
        "        mean_tpr /= n_classes\n",
        "\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        fpr[\"macro\"] = all_fpr\n",
        "        tpr[\"macro\"] = mean_tpr\n",
        "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "        # Plot all ROC curves\n",
        "        plt.figure()\n",
        "        lw = 2\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                label='micro-average ROC curve (area = {0:0.3f})'\n",
        "                    ''.format(roc_auc[\"micro\"]),\n",
        "                color='deeppink', linestyle=':', linewidth=2)\n",
        "\n",
        "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "                label='macro-average ROC curve (area = {0:0.3f})'\n",
        "                    ''.format(roc_auc[\"macro\"]),\n",
        "                color='navy', linestyle=':', linewidth=2)\n",
        "\n",
        "        if len(labels) == 4:\n",
        "            colors = ['green', 'cornflowerblue', 'darkorange', 'darkred']\n",
        "        else:\n",
        "            colors = ['green', 'cornflowerblue', 'darkred']\n",
        "        for label, color in zip(labels, cycle(colors)):\n",
        "            plt.plot(fpr[label], tpr[label], color=color, lw=lw,\n",
        "                    label='ROC curve of {0} (area = {1:0.3f})'\n",
        "                    ''.format(label, roc_auc[label]))\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('ROC curve')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        matplotlib.rcParams.update({'font.size': 14})\n",
        "        plt.savefig('%s.png' % roc_path, pad_inches = 0, bbox_inches='tight')\n",
        "\n",
        "    def save_model(self, checkpoint_path, model=None):\n",
        "        if model is None: model = self.net\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "    \n",
        "    def load_model(self, checkpoint_path, model=None):\n",
        "        print (\"Loading model from %s\" % checkpoint_path)\n",
        "        if model is None: model = self.net\n",
        "        model.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--local_rank\", type=int) # For distributed processing\n",
        "    parser.add_argument(\"--mode\", choices=['train', 'test', 'f1'], required=True)\n",
        "    parser.add_argument(\"--checkpoint\", type=str, required=True)\n",
        "    parser.add_argument(\"--combine_pneumonia\", action='store_true', default=False)\n",
        "    parser.add_argument(\"--save\", type=str)\n",
        "    parser.add_argument(\"--start\", type=int, default=0)\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
        "    parser.add_argument(\"--freeze\", action='store_true', default=False)\n",
        "    parser.add_argument(\"--bs\", type=int, default=8)\n",
        "    parser.add_argument(\"--cm_path\", type=str, default='plots/cm')\n",
        "    parser.add_argument(\"--roc_path\", type=str, default='plots/roc')\n",
        "\n",
        "    # parser.add_argment(\"--torch_version\", \"--tv\", choices=[\"0.3\", \"new\"], default=\"0.3\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    TRAIN_IMAGE_LIST = './data/train.txt'\n",
        "    VAL_IMAGE_LIST = './data/val.txt'\n",
        "    TEST_IMAGE_LIST = './data/test.txt'\n",
        "    TEST_DIR = './data/samples'\n",
        "\n",
        "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "    if args.local_rank is not None:\n",
        "        torch.distributed.init_process_group(backend='nccl')\n",
        "\n",
        "    trainer = Trainer(local_rank=args.local_rank, checkpoint=args.checkpoint, combine_pneumonia=args.combine_pneumonia)\n",
        "    if args.mode == 'test':\n",
        "        trainer.evaluate(TEST_IMAGE_LIST, cm_path=args.cm_path, roc_path=args.roc_path)\n",
        "    elif args.mode == 'train':\n",
        "        assert args.save is not None\n",
        "        trainer.train(TRAIN_IMAGE_LIST, VAL_IMAGE_LIST, BATCH_SIZE=args.bs, NUM_EPOCHS=300, LR=args.lr,\n",
        "                        start_epoch=args.start, save_path=args.save, freeze_feature_layers=args.freeze)\n",
        "    else:\n",
        "        trainer.F1(TEST_DIR, 'models/samples.txt')\n",
        "\n",
        "# Run command for distributed\n",
        "# python -m torch.distributed.launch --nproc_per_node=2 --nnodes=2 --node_rank=0 --master_addr=\"192.168.1.1\" --master_port=1234 OUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3 and all other arguments of our training script)\n",
        "# python -m torch.distributed.launch --nproc_per_node=2 trainer.py --mode train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8pSoZhZrHWJ",
        "colab_type": "text"
      },
      "source": [
        "### inference layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7piK_mwrS4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Script to process set of images and output predictions\n",
        "\"\"\"\n",
        "from RISE.visualize import visualize\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "from covidaid import CovidAID\n",
        "from tqdm import tqdm\n",
        "import termtables as tt\n",
        "\n",
        "\n",
        "\n",
        "class CovidDataLoader(Dataset):\n",
        "    \"\"\"\n",
        "    Read images and corresponding labels.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_dir: path to image directory.\n",
        "            transform: optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.image_names = [img for img in glob.glob(os.path.join(image_dir, '*'))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index: the index of item\n",
        "        Returns:\n",
        "            image and its name\n",
        "        \"\"\"\n",
        "        image_name = self.image_names[index]\n",
        "        image = Image.open(image_name).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, image_name.split('/')[-1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--img_dir\", type=str, required=True)\n",
        "    parser.add_argument(\"--checkpoint\", type=str, required=True)\n",
        "    parser.add_argument(\"--combine_pneumonia\", action='store_true', default=False)\n",
        "    parser.add_argument(\"--visualize_dir\", type=str, default=None)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Load the model\n",
        "    model = CovidAID(args.combine_pneumonia).cuda()\n",
        "    model.load_state_dict(torch.load(args.checkpoint))\n",
        "\n",
        "    # Load the data\n",
        "    normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                     [0.229, 0.224, 0.225])\n",
        "    \n",
        "    test_dataset = CovidDataLoader(image_dir=args.img_dir,\n",
        "            transform=transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.TenCrop(224),\n",
        "                transforms.Lambda\n",
        "                (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "                transforms.Lambda\n",
        "                (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
        "            ])\n",
        "    )\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=64,\n",
        "                    shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "    # initialize the output tensor\n",
        "    pred = torch.FloatTensor().cuda()\n",
        "    pred_names = []\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    for i, (inputs, names) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "        inputs = inputs.cuda()\n",
        "\n",
        "        # Shape of input == [BATCH_SIZE, NUM_CROPS=10, CHANNELS=3, HEIGHT=224, WIDTH=244]\n",
        "        bs, n_crops, c, h, w = inputs.size()\n",
        "        inputs = torch.autograd.Variable(inputs.view(-1, c, h, w), volatile=True)\n",
        "\n",
        "        # Pass through the network and take average prediction from all the crops\n",
        "        output = model(inputs)\n",
        "        output_mean = output.view(bs, n_crops, -1).mean(1)\n",
        "        pred = torch.cat((pred, output_mean.data), 0)\n",
        "        pred_names += names\n",
        "\n",
        "    pred = pred.cpu().numpy()\n",
        "\n",
        "    assert len(pred) == len(pred_names)\n",
        "\n",
        "    scores = []\n",
        "    for p, n in zip(pred, pred_names):\n",
        "        p = [\"%.1f %%\" % (i * 100) for i in p]\n",
        "        scores.append([n] + p)\n",
        "\n",
        "    header=['Name', 'Normal', 'Bacterial', 'Viral', 'COVID-19']\n",
        "    alignment=\"c\"*5\n",
        "    if args.combine_pneumonia:\n",
        "        header = ['Name', 'Normal', 'Pneumonia', 'COVID-19']\n",
        "        alignment = \"c\"*4\n",
        "\n",
        "    string = tt.to_string(\n",
        "        scores,\n",
        "        header=header,\n",
        "        style=tt.styles.ascii_thin_double,\n",
        "        padding=(0, 1),\n",
        "        alignment=alignment\n",
        "    )\n",
        "\n",
        "    print (string)\n",
        "    \n",
        "    # RISE Visualization\n",
        "    if args.visualize_dir:\n",
        "        visualize(model,args.img_dir,args.visualize_dir,CovidDataLoader)\n",
        "        print(\"Visualizations generated at \"+str(args.visualize_dir))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}